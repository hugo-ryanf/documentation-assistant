\# ğŸ’¼ Documentation Assistant



Sistema RAG para busca inteligente em documentaÃ§Ã£o empresarial com IA 100% local.



\## ğŸ¯ Funcionalidades



\- âœ… Consultas em linguagem natural

\- âœ… Respostas baseadas em fontes confiÃ¡veis

\- âœ… CitaÃ§Ã£o automÃ¡tica de documentos e pÃ¡ginas

\- âœ… 100% Local - privacidade total dos dados

\- âœ… Interface web moderna e responsiva



\## ğŸ› ï¸ Tecnologias



\*\*Backend:\*\*

\- Python + FastAPI

\- LangChain

\- Sentence-Transformers (embeddings)

\- FAISS (vector database)

\- Ollama + Mistral (LLM local)



\*\*Frontend:\*\*

\- React + Vite

\- Axios



\## ğŸ“¦ InstalaÃ§Ã£o



\### PrÃ©-requisitos

\- Python 3.11+

\- Node.js 18+

\- Ollama instalado



\### Backend

```bash

cd backend

python -m venv venv



\# Windows

venv\\Scripts\\Activate



\# Mac/Linux

source venv/bin/activate



pip install -r requirements.txt

```



\### LLM Local

```bash

\# Instalar Ollama: https://ollama.com/download

ollama pull mistral

```



\### Frontend

```bash

cd frontend

npm install

```



\## ğŸš€ Como Usar



\### 1. Iniciar Backend

```bash

cd backend

uvicorn app.main:app --reload

```



API disponÃ­vel em: http://localhost:8000



\### 2. Iniciar Frontend

```bash

cd frontend

npm run dev

```



Interface em: http://localhost:5173



\### 3. Upload de Documentos



\- Acesse a interface web

\- FaÃ§a upload de PDFs (manuais, polÃ­ticas, guias)

\- Sistema indexa automaticamente



\### 4. Fazer Perguntas



\- Digite sua pergunta em linguagem natural

\- Receba resposta clara com citaÃ§Ã£o das fontes

\- Clique nas fontes para ver documento original



\## ğŸ“¸ Casos de Uso



\- \*\*RH:\*\* PolÃ­ticas de fÃ©rias, home office, benefÃ­cios

\- \*\*TI:\*\* Procedimentos tÃ©cnicos, troubleshooting

\- \*\*Compliance:\*\* Regulamentos internos, normas

\- \*\*OperaÃ§Ãµes:\*\* Manuais de processo, SOPs



\## ğŸ”’ Privacidade e SeguranÃ§a



\- âœ… Todos os dados processados localmente

\- âœ… Nenhuma informaÃ§Ã£o enviada para APIs externas

\- âœ… LLM roda no prÃ³prio servidor (Ollama)

\- âœ… Embeddings gerados localmente

\- âœ… Ideal para dados sensÃ­veis/confidenciais



\## ğŸ“ Estrutura do Projeto

```

documentation-assistant/

â”œâ”€â”€ backend/

â”‚   â”œâ”€â”€ app/

â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI endpoints

â”‚   â”‚   â”œâ”€â”€ rag\_engine.py    # Sistema RAG

â”‚   â”‚   â”œâ”€â”€ models.py        # Pydantic models

â”‚   â”‚   â””â”€â”€ config.py        # ConfiguraÃ§Ãµes

â”‚   â””â”€â”€ data/

â”‚       â”œâ”€â”€ documentos/      # PDFs indexados

â”‚       â””â”€â”€ faiss\_index/     # Vector database

â””â”€â”€ frontend/

&nbsp;   â””â”€â”€ src/

&nbsp;       â”œâ”€â”€ App.jsx          # Componente principal

&nbsp;       â””â”€â”€ services/        # API client

```



\## ğŸ“ Projeto Educacional



Este projeto foi desenvolvido como estudo de:

\- RAG (Retrieval-Augmented Generation)

\- Sistemas de IA corporativos

\- Processamento de linguagem natural

\- Arquitetura de aplicaÃ§Ãµes full-stack



\## ğŸ“ LicenÃ§a



MIT



\## ğŸ‘¤ Autor



Hugo Ryan - \[GitHub](https://github.com/hugo-ryanf)



