

## ğŸ’¼ DocAssistant - O Sistema de busca inteligente em documentos da sua empresa
<p align="justify">
  <img src="https://img.shields.io/badge/Python-3.11+-blue?logo=python&logoColor=white" alt="Python 3.11+">
  <img src="https://img.shields.io/badge/Node.js-18+-339933?logo=nodedotjs&logoColor=white" alt="Node.js 18+">
  <img src="https://img.shields.io/badge/React-20232A?logo=react&logoColor=61DAFB" alt="React">
  <img src="https://img.shields.io/badge/Vite-B73BFE?logo=vite&logoColor=FFD62E" alt="Vite">
  <img src="https://img.shields.io/badge/FastAPI-005571?logo=fastapi&logoColor=white" alt="FastAPI">
  <img src="https://img.shields.io/badge/Ollama-000000?logo=ollama&logoColor=white" alt="Ollama">
</p>
**Sistema RAG para busca inteligente em documentaÃ§Ã£o empresarial com IA 100% local.**

<img width="1882" height="909" alt="Captura de tela 2026-02-17 214919" src="https://github.com/user-attachments/assets/30c76cab-a60e-41e6-9b27-ce3c6902de99" />


---

## ğŸ“– Sobre o Projeto

Empresas possuem centenas de documentos internos â€” manuais de RH, polÃ­ticas de compliance, guias tÃ©cnicos, procedimentos operacionais â€” espalhados em drives e sistemas. FuncionÃ¡rios perdem tempo valioso procurando informaÃ§Ãµes bÃ¡sicas, sobrecarregando equipes de suporte com perguntas repetitivas.

O **Documentation Assistant** foi criado para resolver este problema. Utilizando uma arquitetura de **GeraÃ§Ã£o Aumentada por RecuperaÃ§Ã£o (RAG)**, este sistema transforma sua documentaÃ§Ã£o em uma base de conhecimento interativa. FuncionÃ¡rios fazem perguntas em linguagem natural e recebem respostas precisas, com citaÃ§Ã£o automÃ¡tica das fontes (documento + pÃ¡gina), geradas por um modelo de linguagem local (Mistral 7B via Ollama) que garante total privacidade dos dados corporativos.

**Ideal para:** Onboarding de novos funcionÃ¡rios, suporte ao RH/TI, compliance interno, e qualquer cenÃ¡rio onde documentaÃ§Ã£o precisa ser acessÃ­vel e auditÃ¡vel.

---

## âœ¨ Funcionalidades Principais

- ğŸ’¬ **Consultas em Linguagem Natural:** "Como solicitar fÃ©rias?" ou "Qual a polÃ­tica de home office?" â€” pergunte como se estivesse conversando com um colega.
- ğŸ¯ **Respostas Baseadas em Fontes:** Todas as respostas sÃ£o construÃ­das a partir de trechos relevantes extraÃ­dos dos seus documentos, evitando "alucinaÃ§Ãµes" da IA.
- ğŸ” **VisualizaÃ§Ã£o das Fontes:** Cada resposta mostra exatamente qual documento (e pÃ¡gina) foi usado, permitindo auditoria completa.
- ğŸ“¤ **Upload Simples de PDFs:** Interface para adicionar novos documentos que sÃ£o automaticamente indexados.
- ğŸ”’ **Arquitetura 100% Local:** LLM, embeddings e dados ficam no seu servidor. Nenhuma informaÃ§Ã£o Ã© enviada para APIs externas â€” perfeito para dados sensÃ­veis e conformidade com LGPD.

---

## ğŸ› ï¸ Tecnologias Utilizadas

**Backend:**
- **API Framework:** FastAPI
- **OrquestraÃ§Ã£o RAG:** LangChain
- **Embeddings:** Sentence-Transformers (`all-MiniLM-L6-v2`)
- **Vector Store:** FAISS (Facebook AI Similarity Search)
- **LLM Local:** Ollama + Mistral 7B
- **Processamento de PDFs:** PyPDF

**Frontend:**
- **Framework:** React + Vite
- **HTTP Client:** Axios
- **EstilizaÃ§Ã£o:** CSS moderno com design responsivo

**Infraestrutura:**
- **Linguagem:** Python 3.11+ | Node.js 18+
- **ContainerizaÃ§Ã£o:** Docker (opcional)

---

## ğŸš€ Como Executar Localmente

### PrÃ©-requisitos
- Python 3.11+
- Node.js 18+
- [Ollama instalado](https://ollama.com/download)
- Git

### 1. Clone o RepositÃ³rio
```bash
git clone https://github.com/hugo-ryanf/documentation-assistant.git
cd documentation-assistant
```

### 2. ConfiguraÃ§Ã£o do Backend
```bash
cd backend

# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# No Windows:
venv\Scripts\activate
# No Mac/Linux:
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 3. Configurar LLM Local (Ollama)
```bash
# Baixar modelo Mistral (a primeira vez exige download de ~4GB)
ollama pull mistral

# Verificar instalaÃ§Ã£o
ollama list
```

### 4. Iniciar o Backend
```bash
# Na pasta backend/ com venv ativado:
uvicorn app.main:app --reload
```
- A API estarÃ¡ disponÃ­vel em: `http://localhost:8000`
- DocumentaÃ§Ã£o interativa (Swagger): `http://localhost:8000/docs`

### 5. ConfiguraÃ§Ã£o do Frontend
Em um **novo terminal**:
```bash
cd frontend

# Instalar dependÃªncias
npm install

# Iniciar aplicaÃ§Ã£o
npm run dev
```
- A Interface web estarÃ¡ disponÃ­vel em: `http://localhost:5173`

### 6. Upload de Documentos e Uso
1. Acesse `http://localhost:5173`
2. FaÃ§a upload de PDFs (manuais, polÃ­ticas, guias internos).
3. Aguarde a indexaÃ§Ã£o automÃ¡tica.
4. Digite sua pergunta: *"Como solicitar reembolso?"*
5. Receba a resposta com as fontes citadas!

---

## ğŸ“ Estrutura do Projeto

```text
documentation-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # Endpoints FastAPI
â”‚   â”‚   â”œâ”€â”€ rag_engine.py        # Motor RAG (indexaÃ§Ã£o + busca)
â”‚   â”‚   â”œâ”€â”€ models.py            # Modelos Pydantic
â”‚   â”‚   â””â”€â”€ config.py            # ConfiguraÃ§Ãµes (paths, modelos)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ documentos/          # PDFs carregados (nÃ£o versionado)
â”‚   â”‚   â”œâ”€â”€ faiss_index/         # Ãndice vetorial (nÃ£o versionado)
â”‚   â”‚   â””â”€â”€ metadata.json        # Metadados dos chunks
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx              # Componente principal
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SearchBar.jsx
â”‚   â”‚   â”‚   â””â”€â”€ SourceViewer.jsx
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.js           # Client HTTP (Axios)
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ screenshot.png           # Print da aplicaÃ§Ã£o
â”œâ”€â”€ tests/                       # Testes automatizados
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸ¯ Casos de Uso

**Recursos Humanos**
- "Qual o processo para solicitar fÃ©rias?"
- "Como funciona o reembolso de despesas?"
- "Qual a polÃ­tica de home office?"

**TI e Suporte TÃ©cnico**
- "Como resetar a senha da VPN?"
- "Qual o procedimento para solicitar novo equipamento?"
- "Qual a polÃ­tica de backup de dados?"

**Compliance e JurÃ­dico**
- "Quais sÃ£o as diretrizes de LGPD da empresa?"
- "Quais sÃ£o as normas de seguranÃ§a da informaÃ§Ã£o?"
- "Qual o procedimento para tratamento de dados pessoais?"

**OperaÃ§Ãµes**
- "Manual de uso do sistema X"
- "Checklist de abertura de loja"
- "SOPs de atendimento ao cliente"

---

## ğŸ”’ Privacidade e SeguranÃ§a

**Por que 100% local Ã© importante:**
- âœ… **Conformidade LGPD:** Dados sensÃ­veis nunca saem do servidor da empresa.
- âœ… **Sem vazamentos:** Nenhuma pergunta ou documento Ã© enviado para OpenAI, Anthropic ou qualquer API externa.
- âœ… **Auditabilidade completa:** Toda resposta cita a fonte exata, permitindo verificaÃ§Ã£o.
- âœ… **Controle total:** VocÃª escolhe quais documentos indexar e quando atualizÃ¡-los.
- âœ… **Sem custos recorrentes:** Sem cobranÃ§a por tokens ou chamadas de API.

**Arquitetura de privacidade:**
- LLM roda via Ollama (local).
- Embeddings gerados localmente (Sentence-Transformers).
- Vector store armazenado em disco (FAISS).
- PDFs permanecem no servidor.

---

## ğŸ“Š Performance

Benchmarks tÃ­picos *(hardware mÃ©dio - Intel i5, 16GB RAM)*:

| OperaÃ§Ã£o | Tempo Estimado |
| :--- | :--- |
| IndexaÃ§Ã£o de 1 PDF (20 pÃ¡ginas) | ~15-30s |
| Busca vetorial (top 5 chunks) | ~200ms |
| GeraÃ§Ã£o de resposta (LLM) | ~3-8s |
| **Total por pergunta** | **~4-10s** |

**OtimizaÃ§Ãµes possÃ­veis:**
- GPU acceleration (Ollama com CUDA).
- Cache de respostas frequentes.
- FAISS GPU para datasets grandes (10k+ documentos).

---

## ğŸ—ºï¸ Roadmap

**v1.0 (Atual)**
- [x] RAG bÃ¡sico funcionando
- [x] Upload de PDFs
- [x] Interface web React
- [x] CitaÃ§Ã£o de fontes

**v1.1 (PrÃ³ximo)**
- [ ] Upload via drag & drop na interface
- [ ] AutenticaÃ§Ã£o de usuÃ¡rios
- [ ] HistÃ³rico de conversas
- [ ] Feedback (Ãºtil/nÃ£o Ãºtil)

**v2.0 (Futuro)**
- [ ] Suporte a mÃºltiplos formatos (DOCX, TXT, HTML)
- [ ] CategorizaÃ§Ã£o automÃ¡tica de documentos
- [ ] Dashboard de analytics (perguntas mais frequentes)
- [ ] Modo admin para gestÃ£o de documentos
- [ ] API de integraÃ§Ã£o (Slack, Teams, WhatsApp)

---
## ğŸ‘¤ Autor

**Hugo Ryan**
- GitHub: [@hugo-ryanf](https://github.com/hugo-ryanf)
- LinkedIn: [@hugo-ryan](https://www.linkedin.com/in/hugo-ryan-9b5621201/)
- Email: [@hugoryanf](hugoryanf@gmail.com)
